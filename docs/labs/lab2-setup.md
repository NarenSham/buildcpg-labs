# Lab 2: Market Sentiment Analysis - Setup Guide

Complete setup instructions for the Market Sentiment Analysis lab with step-by-step commands and configurations.

## Prerequisites

Before starting, ensure you have:

- **Python 3.11+** installed
- **Git** for version control
- **2GB disk space** available
- **BuildCPG Labs** root repository cloned
- **Terminal** access (Mac/Linux) or WSL2 (Windows)

Check prerequisites:
```bash
python3 --version  # Should show 3.11.x or higher
git --version      # Should show 2.x or higher
df -h             # Check disk space
```

## Directory Structure

Understanding the lab structure before setup:

```
lab2_market_sentiment/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Source CSV files
â”‚   â”‚   â”œâ”€â”€ reddit_real.csv         # Generated by ingestion
â”‚   â”‚   â””â”€â”€ news_real.csv           # Generated by ingestion
â”‚   â”œâ”€â”€ bronze/                     # dbt staging output
â”‚   â”œâ”€â”€ silver/                     # dbt intermediate output
â”‚   â”œâ”€â”€ gold/                       # dbt marts output
â”‚   â””â”€â”€ lab2_market_sentiment.duckdb  # Main database file
â”‚
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_reddit__posts.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_news__articles.sql
â”‚   â”‚   â”‚   â””â”€â”€ _sources.yml
â”‚   â”‚   â”œâ”€â”€ intermediate/
â”‚   â”‚   â”‚   â””â”€â”€ int_sentiment_unified.sql
â”‚   â”‚   â””â”€â”€ mart/
â”‚   â”‚       â”œâ”€â”€ fct_sentiment_events.sql
â”‚   â”‚       â””â”€â”€ mart_daily_sentiment.sql
â”‚   â”œâ”€â”€ macros/
â”‚   â”‚   â”œâ”€â”€ generate_surrogate_key.sql
â”‚   â”‚   â”œâ”€â”€ validate_sentiment.sql
â”‚   â”‚   â””â”€â”€ get_current_timestamp.sql
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_no_future_dates.sql
â”‚   â”‚   â”œâ”€â”€ test_sentiment_range.sql
â”‚   â”‚   â””â”€â”€ test_mart_daily_has_all_brands.sql
â”‚   â”œâ”€â”€ dbt_project.yml              # Project configuration
â”‚   â”œâ”€â”€ profiles.yml                 # Database connection
â”‚   â”œâ”€â”€ packages.yml                 # dbt packages
â”‚   â””â”€â”€ schema.yml                   # Model contracts & tests
â”‚
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ ingest_sentiment.py          # Data generation script
â”‚
â”œâ”€â”€ lab2_env/                        # Virtual environment (created during setup)
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # Lab documentation
```

## Step 1: Navigate to Lab 2

From the BuildCPG Labs root:

```bash
cd buildcpg-labs/lab2_market_sentiment

# Verify you're in the right place
pwd
# Should show: /path/to/buildcpg-labs/lab2_market_sentiment

ls
# Should show: data/ dbt/ pipelines/ requirements.txt README.md
```

## Step 2: Create Virtual Environment

Create an isolated Python environment for Lab 2:

```bash
# Create virtual environment
python3 -m venv lab2_env

# Activate it (Mac/Linux)
source lab2_env/bin/activate

# Activate it (Windows WSL2)
source lab2_env/bin/activate

# Verify activation (prompt should show lab2_env)
which python
# Should show: /path/to/lab2_market_sentiment/lab2_env/bin/python
```

**Troubleshooting:**
- If activation fails on Mac: Try `source ./lab2_env/bin/activate`
- If Python not found: Use `python3 -m venv lab2_env`
- If permission denied: Check folder permissions with `ls -la`

## ðŸ“¦ Step 3: Install Python Dependencies

Install all required packages:

```bash
# Upgrade pip first
pip install --upgrade pip

# Install requirements
pip install -r requirements.txt

# Verify installations
pip list | grep -E "dbt|duckdb|pandas"
```

**Expected output:**
```
dbt-core                  1.7.0
dbt-duckdb                1.7.0
duckdb                    0.9.1
pandas                    2.1.4
numpy                     1.26.2
pyyaml                    6.0.1
```

**Dependencies include:**
- `dbt-duckdb==1.7.0` - dbt adapter for DuckDB
- `duckdb==0.9.1` - Embedded database
- `pandas>=2.0.0` - Data manipulation
- `numpy>=1.24.0` - Numerical computing
- `pyyaml>=6.0` - Configuration parsing

**Troubleshooting:**
- If installation fails: Try `pip install --no-cache-dir -r requirements.txt`
- If dbt-duckdb fails: Install separately with `pip install dbt-duckdb==1.7.0`
- If memory errors: Install packages one at a time

## Step 4: Install dbt Packages

Install external dbt packages for data quality testing:

```bash
cd dbt

# Install packages
dbt deps

# Expected output:
# Installing calogica/dbt_expectations
# Installed from version 0.10.4
# Installing calogica/dbt_date
# Installed from version 0.10.1
```

**Packages installed:**
- `calogica/dbt_expectations` - Advanced data quality tests
- `calogica/dbt_date` - Date utility functions

**Package location:** `dbt/dbt_packages/`

**Troubleshooting:**
- If deps fails: Delete `dbt_packages/` folder and retry
- If network error: Check internet connection
- If version conflicts: Update `packages.yml` versions

## Step 5: Configure dbt Profile

Verify database connection settings:

```bash
# Check profiles.yml exists
ls -la profiles.yml

# View configuration
cat profiles.yml
```

**Expected `profiles.yml` content:**

```yaml
lab2_market_sentiment:
  outputs:
    dev:
      type: duckdb
      path: ../data/lab2_market_sentiment.duckdb
      threads: 4
      
  target: dev
```

**Key settings:**
- `type: duckdb` - Use DuckDB adapter
- `path: ../data/lab2_market_sentiment.duckdb` - Database location (relative to dbt/)
- `threads: 4` - Parallel execution threads
- `target: dev` - Default environment

**If file doesn't exist, create it:**

```bash
cat > profiles.yml << 'EOF'
lab2_market_sentiment:
  outputs:
    dev:
      type: duckdb
      path: ../data/lab2_market_sentiment.duckdb
      threads: 4
  target: dev
EOF
```

## Step 6: Verify dbt Setup

Test dbt configuration:

```bash
# Must be in dbt/ directory
pwd  # Should show: /path/to/lab2_market_sentiment/dbt

# Run dbt debug
dbt debug
```

**Expected output:**

```
Running with dbt=1.7.0
âœ… Connection test: OK
âœ… All checks passed!
```

**What dbt debug checks:**
1. Python version compatibility
2. dbt installation
3. Profile configuration
4. Database connection
5. Project configuration

**Troubleshooting:**
- `Profile not found`: Check profiles.yml name matches dbt_project.yml
- `Connection failed`: Verify path in profiles.yml is correct
- `Python version`: Ensure Python 3.11+

## Step 7: Generate Sample Data

Generate synthetic sentiment data:

```bash
# Go back to lab root
cd ..

# Run data generation script
python pipelines/ingest_sentiment.py
```

**Expected output:**
```
ðŸ”„ Fetching Reddit data...
Reddit data ingested: 500 records â†’ data/raw/reddit_real.csv
ðŸ”„ Fetching news data...
News data ingested: 300 records â†’ data/raw/news_real.csv
Ingestion complete.
```

**Files created:**
- `data/raw/reddit_real.csv` (500 records)
- `data/raw/news_real.csv` (300 records)

**Data includes:**
- 5 CPG brands: Coca-Cola, PepsiCo, Unilever, Procter & Gamble, NestlÃ©
- Sentiment scores: -1 (negative) to 1 (positive)
- Timestamps: Last 90 days
- Engagement metrics: Upvotes, comments, shares

**Verify data:**
```bash
# Check files exist
ls -lh data/raw/

# View first few lines
head -5 data/raw/reddit_real.csv
head -5 data/raw/news_real.csv

# Count rows
wc -l data/raw/*.csv
```

## Step 8: Run dbt Pipeline

Execute the complete data transformation pipeline:

```bash
cd dbt

# Run with full refresh (first time)
dbt build --full-refresh
```

**What happens:**

1. **Staging models** (2 models)
   - `stg_reddit__posts` - Clean Reddit data
   - `stg_news__articles` - Clean news data

2. **Intermediate model** (1 model)
   - `int_sentiment_unified` - Unified data with business logic

3. **Mart models** (2 models)
   - `fct_sentiment_events` - Fact table
   - `mart_daily_sentiment` - Daily aggregates

4. **Data quality tests** (14 tests)
   - Uniqueness checks
   - Not null validations
   - Range validations
   - Accepted values
   - Custom business logic

**Expected output:**
```
Running with dbt=1.7.0
Found 5 models, 14 tests

1 of 17 START sql table model main.sentiment_unified .............. [RUN]
1 of 17 OK created sql table model main.sentiment_unified ......... [OK in 0.42s]

2 of 17 START sql incremental model main.sentiment_events ......... [RUN]
2 of 17 OK created sql incremental model main.sentiment_events .... [OK in 0.22s]

[... tests running ...]

Completed successfully
âœ… PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=17
```

**Build time:** ~2-3 seconds with sample data

**Troubleshooting:**
- If duplicates error: See [Troubleshooting Guide](lab2-troubleshooting.md#duplicate-sentiment_event_id)
- If contract error: Check data types match schema.yml
- If test fails: Run `dbt test` alone to isolate issue

## Step 9: Verify Data Creation

Check that all tables were created:

```bash
# List all models
dbt ls --resource-type model
```

**Expected output:**
```
stg_reddit__posts
stg_news__articles
int_sentiment_unified
fct_sentiment_events
mart_daily_sentiment
```

**Check row counts:**

```python
# From lab2_market_sentiment directory
python -c "
import duckdb
conn = duckdb.connect('data/lab2_market_sentiment.duckdb')

# Check staging
print('Staging:')
print(f\"Reddit: {conn.execute('SELECT COUNT(*) FROM main.stg_reddit__posts').fetchone()[0]} rows\")
print(f\"News: {conn.execute('SELECT COUNT(*) FROM main.stg_news__articles').fetchone()[0]} rows\")

# Check intermediate
print(f\"\nIntermediate:\")
print(f\"Unified: {conn.execute('SELECT COUNT(*) FROM main.sentiment_unified').fetchone()[0]} rows\")

# Check marts
print(f\"\nMarts:\")
print(f\"Events: {conn.execute('SELECT COUNT(*) FROM main.sentiment_events').fetchone()[0]} rows\")
print(f\"Daily: {conn.execute('SELECT COUNT(*) FROM main.mart_daily_sentiment').fetchone()[0]} rows\")

conn.close()
"
```

**Expected output:**
```
Staging:
Reddit: 500 rows
News: 300 rows

Intermediate:
Unified: 800 rows

Marts:
Events: 800 rows
Daily: [varies by date range]
```

## Step 10: Run Data Quality Tests

Execute all data quality tests:

```bash
cd dbt

# Run all tests
dbt test
```

**Tests executed (14 total):**

1. **Uniqueness Tests (2)**
   - `unique_fct_sentiment_events_sentiment_event_id`
   - `expect_compound_columns_to_be_unique_mart_daily_sentiment`

2. **Not Null Tests (4)**
   - `not_null_fct_sentiment_events_sentiment_event_id`
   - `not_null_fct_sentiment_events_brand_key`
   - `not_null_fct_sentiment_events_sentiment_score`
   - `not_null_fct_sentiment_events_published_date`

3. **Range Tests (2)**
   - `expect_column_values_to_be_between_sentiment_score` (-1 to 1)
   - `test_sentiment_range`

4. **Accepted Values Tests (2)**
   - `accepted_values_quality_flag`
   - `accepted_values_anomaly_flag`

5. **Custom Business Logic Tests (4)**
   - `test_no_future_dates`
   - `test_mart_daily_has_all_brands`
   - Additional custom validations

**Expected output:**
```
âœ… PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
```

**If tests fail:** See [Troubleshooting Guide](lab2-troubleshooting.md)

## Step 11: Generate Documentation

Create and view dbt documentation:

```bash
# Generate docs
dbt docs generate

# Serve docs locally
dbt docs serve
```

**What's included:**
- Model lineage diagram
- Column descriptions
- Test results
- SQL code
- Relationships

**Access documentation:** http://localhost:8080

**View in browser:**
- Navigate model DAG (Directed Acyclic Graph)
- Click models to see details
- View SQL compilation
- See test results

**Stop server:** Press `Ctrl+C`

## Step 12: Test Incremental Runs

Test that incremental models work correctly:

```bash
# Generate more data
cd ..
python pipelines/ingest_sentiment.py

# Run incrementally (only new data)
cd dbt
dbt run

# Should process only new records
# Expected output: "Inserted X rows" or "No new data"
```

**Incremental behavior:**
- `fct_sentiment_events`: Only inserts records with `published_at > MAX(published_at)`
- `mart_daily_sentiment`: Only processes new dates

## Configuration Files Reference

### dbt_project.yml

```yaml
name: 'lab2_market_sentiment'
version: '1.0.0'
profile: 'lab2_market_sentiment'

config-version: 2

model-paths: ["models"]
test-paths: ["tests"]
macro-paths: ["macros"]
target-path: "target"
clean-targets: ["target", "dbt_packages", "logs"]

models:
  lab2_market_sentiment:
    staging:
      +materialized: view
      +tags: ['staging']
    intermediate:
      +materialized: table
      +tags: ['intermediate']
    mart:
      +materialized: incremental
      +tags: ['mart']

vars:
  sentiment_threshold_positive: 0.3
  sentiment_threshold_negative: -0.3
```

### packages.yml

```yaml
packages:
  - package: calogica/dbt_expectations
    version: 0.10.4
  - package: calogica/dbt_date
    version: 0.10.1
```

**Note:** Consider upgrading to `metaplane/dbt_expectations` (newer version)

### requirements.txt

```txt
dbt-duckdb==1.7.0
duckdb==0.9.1
pandas>=2.0.0
numpy>=1.24.0
pyyaml>=6.0
```

## Common Commands Reference

### Data Generation
```bash
python pipelines/ingest_sentiment.py  # Generate new data
```

### dbt Operations
```bash
dbt deps                    # Install packages
dbt debug                   # Verify setup
dbt compile                 # Compile SQL
dbt run                     # Run models
dbt run --full-refresh      # Full rebuild
dbt run --select model_name # Run specific model
dbt test                    # Run tests
dbt test --select model_name  # Test specific model
dbt docs generate           # Generate docs
dbt docs serve              # Serve docs
dbt clean                   # Clean artifacts
dbt ls                      # List resources
```

### Database Operations
```bash
# Connect to database
python -c "import duckdb; conn = duckdb.connect('data/lab2_market_sentiment.duckdb'); print(conn.execute('SHOW TABLES').fetchall())"

# Vacuum database
python -c "import duckdb; conn = duckdb.connect('data/lab2_market_sentiment.duckdb'); conn.execute('VACUUM'); print('Done')"
```

## Troubleshooting Quick Reference

| Issue | Solution |
|-------|----------|
| dbt deps fails | `rm -rf dbt_packages/ && dbt deps` |
| Database locked | Close all connections, retry |
| Tests fail | `dbt test --select [test_name]` |
| Duplicates | See [full guide](lab2-troubleshooting.md) |
| Contract error | Match data types in schema.yml |
| Profile not found | Check profiles.yml name |

**Full troubleshooting:** See [Lab 2 Troubleshooting](lab2-troubleshooting.md)

## Setup Verification Checklist

Before proceeding, verify:

- [ ] Virtual environment activated (`lab2_env`)
- [ ] All dependencies installed (`pip list`)
- [ ] dbt packages installed (`dbt_packages/`)
- [ ] dbt debug passes (`âœ… All checks passed`)
- [ ] Sample data generated (800 total rows)
- [ ] All 5 models created (check with `dbt ls`)
- [ ] All 14 tests passing (`dbt test`)
- [ ] Database file exists (`data/lab2_market_sentiment.duckdb`)
- [ ] Documentation generated (`dbt docs generate`)

## Next Steps

After successful setup:

1. **Explore Data Models** - See [Data Models Reference](lab2-data-models.md)
2. **Run Sample Queries** - See [Quick Reference](lab2-quick-reference.md)
3. **Understand Architecture** - See [Lab 2 Overview](lab2-overview.md)
4. **Plan Real API Integration** - Upgrade from synthetic to real data
5. **Build Dashboard** - Create Streamlit visualization

## Incremental Updates

For subsequent runs:

```bash
# Activate environment
source lab2_env/bin/activate

# Generate new data
python pipelines/ingest_sentiment.py

# Run incrementally
cd dbt
dbt run  # Only processes new data

# Run tests
dbt test
```

## Cleanup & Reset

To start fresh:

```bash
# Clean dbt artifacts
cd dbt
dbt clean

# Delete database
rm ../data/lab2_market_sentiment.duckdb

# Rebuild from scratch
dbt build --full-refresh
```

## Getting Help

- **Setup Issues:** See [Troubleshooting](./troubleshooting.md)
- **Model Questions:** See [Data Models](lab2-architecture.md)
- **Quick Reference:** See [Quick Reference](lab2-quick-reference.md)
- **General Help:** See [Main Documentation](../index.md)

---

**Setup Time:** ~10-15 minutes  
**Difficulty:** Intermediate  
**Prerequisites:** Python, Git, Terminal basics  
**Last Updated:** November 2025  
**Maintainer:** narensham